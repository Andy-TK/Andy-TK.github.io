---
layout:     post   				    # 使用的布局（不需要改）
title:      统计机器学习 11：核方法   	# 标题 
subtitle:   墨尔本大学 COMP90051 课程笔记 #副标题
date:       2019-11-16 				# 时间
author:     Andy 						# 作者
header-img: img/post-bg-sml.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 统计机器学习
    - SVM
    - 拉格朗日对偶
---

<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

# Lecture 11 核方法
## 主要内容
* **核化**
  * SVM 对偶公式的基扩展
  * “核技巧”；特征空间点积的快速计算
* **模块化学习**
  * 从特征变换中分离出“学习模块”
  * 表示定理
* **构造核**
  * 常见核及其特性概述
  * Mercer 定理
  * 学习非常规数据类型

## 1. SVM 核化
**通过基扩展进行特征变换；通过对核进行直接评估来实现加速 —— “核技巧”**
### 1.1 SVM 处理非线性数据
* 方法 1：软间隔 SVM（参考 Lecture 10）
* 方法 2：**特征空间** 变换（参考 Lecture 4）
  * 将数据映射到一个新的特征空间
  * 在新的特征空间中运行硬间隔或者软间隔 SVM
  * 决策边界在原始特征空间中是非线性的  
  <img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-14-WX20200214-133247%402x.png" width="80%">

### 1.2 特征变换（基扩展）
* 考虑一个二分类问题
* 每个样本点具有特征 $[x_1, x_2]$
* 非线性可分  
<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-14-WX20200214-133923%402x.png" width="40%">

* 现在“增加”一个特征 $x_3=x_1^2+x_2^2$
* 每个样本点现在为 $[x_1, x_2, x_1^2+x_2^2]$
* 现在数据变成线性可分了  
<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-14-WX20200214-134026%402x.png" width="40%">

### 1.3 朴素工作流
* 选择 / 设计一个线性模型
* 选择 / 设计一个高维变换 $\varphi (x)$
  * 希望在添加了许多各种特征之后，其中一些特征将使数据变得线性可分
* 对于 **每个** 训练样本，以及 **每个** 新的实例，计算 $\varphi (x)$
* 训练分类器 / 进行预测
* **问题：** 对于高维 / 无限维的 $\varphi (x)$，**计算 $\varphi (x)$ 是不现实 / 不可能的**

### 1.4 硬间隔 SVM 的对偶公式
* **训练：** 寻找 $\lambda$ 使得  

$$\begin{array}{cc}\mathop{\operatorname{arg\,max}}\limits_{\lambda}\sum_{i=1}^{n}\lambda_i-\dfrac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}\lambda_i \lambda_j y_i y_j \color{red}{\underbrace{\fbox{$\color{black}{\boldsymbol x_i' \boldsymbol x_j}$}}_{\text{点积}}}\\\\
\text{s.t.}\quad \lambda_i\ge 0 \;\text{and}\;\sum_{i=1}^{n}\lambda_i y_i=0 \end{array}$$

* **预测：** 根据 $s$ 的符号对实例 $\boldsymbol x$ 进行分类  

$$s=b^*+\sum_{i=1}^{n}\lambda_i^* y_i \color{red}{\underbrace{\fbox{$\color{black}{\boldsymbol x_i' \boldsymbol x}$}}_{\text{点积}}}$$

注意：对于任意支持向量 $j$，通过求解 $$y_j(b^{*}+\sum_{i=1}^{n}\lambda_i^* y_i \color{red}{\fbox{$\color{black}{\boldsymbol x_i' \boldsymbol x_j}$}})=1$$ 来找到 $b^*$

### 1.5 特征空间中的硬间隔 SVM



---

## 总结
* 软间隔 SVM
  * 直觉和问题的数学表述
* 构造对偶问题
  * 拉格朗日乘子法、KKT 条件
  * 弱对偶和强对偶
* 补充
  * 互补松弛性
  * 训练注意事项

下节内容：核方法


