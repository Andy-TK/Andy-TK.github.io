I":!<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-00-03-线性文本分类">Lecture 00-03 线性文本分类</h1>

<blockquote>
  <p>参考资料：Natural Language Processing: Chapter 2 - Linear text classiﬁcation (p.13-46) —— by Jacob Eisenstein</p>
</blockquote>

<h2 id="引言">引言</h2>
<p>我们从 <strong>文本分类</strong> 问题开始：给定一个文本文档，为其分配一个离散标签 $y\in \mathcal Y$，其中 $\mathcal Y$ 是可能标签的集合。文本分类有着很广泛的应用，从垃圾邮件过滤到电子健康记录分析等等。本章从数学的角度描述了一些最著名的应用和最高效的文本分类算法，这应该有助于你理解这些算法的作用以及为什么起作用。文本分类也是更复杂的自然语言处理任务的基础。对于没有机器学习或统计学背景的读者来说，本章中的材料要比后面的大部分内容花费更多的时间来消化。但是，这些投入的时间终将获得回报，因为这些基本分类算法背后的数学原理会在本书其他章节的内容中反复出现。</p>

<h2 id="1-词袋模型">1. 词袋模型</h2>
<p>为了实现文本分类，第一个问题是如何表示每个文档或实例。一种常见方法是使用单词计数的列向量，例如 $\boldsymbol x = [0,1,1,0,0,2,0,1,13,0…]^{\top}$，其中 $x_j$ 是单词 $j$ 的计数。$\boldsymbol x$ 的长度为 $V\triangleq |\mathcal V|$，其中 $\mathcal V$ 是词汇表中可能单词的集合。在线性分类中，分类决策基于单个特征计数（例如，单词计数）的加权和。</p>

<p>对象 $\boldsymbol x$ 是一个向量，但通常称为一个 <strong>词袋（bag of words）</strong>，因为它仅包含每个单词计数的相关信息，而不包含单词出现的顺序信息。在词袋表示法下，我们将忽略语法、句子边界、段落 —— 等等除了单词之外的一切。然而，词袋模型对于文本分类却出奇地有效。如果你在某个文档中看到 <em>“$whale$（鲸鱼）”</em> 一词，那么该文档是 <em>$\rm{fiction}$（虚构的）</em> 还是 <em>$\rm{nonﬁction}$（非虚构的）</em>？如果你看的是 <em>“$molybdenum$（钼）”</em> 这个词呢？对于许多标签问题，单个单词可以作为强大的预测指标。</p>

<p>为了从一个词袋中预测出一个标签，我们可以为词汇表中的每个单词分配一个分数，以衡量与该标签的兼容性。例如，对于标签 $\rm{FICTION}$，我们可以分配一个正的分数给单词 $whale$ ，分配一个负的分数给单词 $molybdenum$。这些得分称为 <strong>权重</strong>，它们被排列在一个列向量 $\boldsymbol \theta$ 中。</p>

<p>现在，假设你想要一个多分类器，其中，$K\triangleq |\mathcal Y|&gt;2$。例如，你可能想对有关体育、名人、音乐和商业的新闻报道进行分类。目标是在给定词袋 $\boldsymbol x$ 的情况下，利用权重 $\boldsymbol \theta$ 预测出一个标签 $\hat y$。对于每个标签 $y\in \mathcal Y$，我们计算出一个分数 $\Psi(\boldsymbol x,y)$，这是词袋 $\boldsymbol x$ 与标签 $y$ 之间兼容性的一个标量度量。在线性词袋分类器中，该分数是权重 $\boldsymbol \theta$ 与 <strong>特征函数</strong> $\boldsymbol f(\boldsymbol x,y)$ 的输出之间的向量内积：</p>

<script type="math/tex; mode=display">\Psi(\boldsymbol x,y)= \boldsymbol \theta \cdot \boldsymbol f(\boldsymbol x,y)=\sum_{j}\theta_j f_j(\boldsymbol x,y)  \tag{1}\label{(1)}</script>

<p>如上所示，$\boldsymbol f$ 函数具有两个参数，单词计数 $\boldsymbol x$ 和标签 $y$，并且返回一个向量输出。例如，给定参数 $\boldsymbol x$  和 $y$，该特征向量的元素 $j$ 可能为：</p>

<script type="math/tex; mode=display">% <![CDATA[
f_j(\boldsymbol x,y)=\begin{cases}x_{whale}, & \text{if}\; y= \rm{FICTION}\\
0, & \rm{otherwise}\end{cases} \tag{2} %]]></script>

<p>如果标签为 $\rm{FICTION}$，则此函数返回单词 $whale$ 的计数，否则返回零。索引 $j$ 取决于 $whale$ 在词汇表中的位置，以及 $\rm{FICTION}$ 在可能的标签集合中的位置。然后，相应的权重 $\theta_j$ 对单词 $whale$ 和标签 $\rm{FICTION}$ 之间的兼容性进行打分。正的分数表示该单词使得该标签可能性更大。</p>

<p>特征函数的输出可以形式化为一个向量：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\boldsymbol f(\boldsymbol x,y=1) &= [\boldsymbol x;\underbrace{0;0;...;0}_{(K-1)\times V}]  \tag{3}\\
\boldsymbol f(\boldsymbol x,y=2) &= [\underbrace{0;0;...;0}_{V} ;\boldsymbol x;\underbrace{0;0;...;0}_{(K-2)\times V}]  \tag{4}\\
\boldsymbol f(\boldsymbol x,y=K) &= [\underbrace{0;0;...;0}_{(K-1)\times V};\boldsymbol x]  \tag{5}
\end{align} %]]></script>

<p>其中，$[\underbrace{0;0;…;0}_{(K-1)\times V}]$ 是由 $(K-1)\times V$ 个零组成的一个列向量，分号表示垂直串联。对于 $K$ 个可能标签中的每一个，特征函数都会返回一个向量，该向量中的大多数元素都为零，而在其中某个位置则会插入一个单词计数 $\boldsymbol x$ 的列向量，插入的位置与某个特定的标签 $y$ 有关。这种表示方式如 <a href="#fig1">图 1</a> 所示。这种表示方法初看可能有些笨拙，但是它将学习设定推广到了一个令人印象深刻的范围，尤其是 <strong>结构预测</strong>。</p>

<p>给定一个权重向量 $\boldsymbol \theta \in \mathbb R^{VK}$，我们现在可以通过公式 $\eqref{(1)}$ 计算出分数 $\Psi(\boldsymbol x,y)$。该内积给出了观测 $\boldsymbol x$ 与标签 $y$ 之间兼容性的一个标量度量。对于任何文档 $\boldsymbol x$，我们预测标签 $\hat y$：</p>

<script type="math/tex; mode=display">\hat y=\mathop{\operatorname{arg\,max}}\limits_{y\in \mathcal Y}\Psi(\boldsymbol x,y)  \tag{6}</script>

<script type="math/tex; mode=display">\Psi(\boldsymbol x,y)=\boldsymbol \theta \cdot \boldsymbol f(\boldsymbol x,y)  \tag{7}</script>

<p>这种内积的表示方法清晰地将数据（$\boldsymbol x$ 和 $y$）和参数（$\boldsymbol \theta$）分割开来。</p>

<p>在表示和分析时，我们采用向量符号；而在代码中，权重和特征向量可以通过字典实现。然后内积可以通过循环计算。在python中：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">weights</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span> 
    <span class="k">for</span> <span class="n">feature</span><span class="p">,</span><span class="n">count</span> <span class="ow">in</span> <span class="n">feature_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">*</span> <span class="n">count</span> 
    <span class="k">return</span> <span class="n">total</span>
</code></pre></div></div>

<p>这种表示方法有很多好处，它避免了在大量计数为零的特征上的存储与迭代。</p>

<p>通常，会在单词计数向量 $\boldsymbol x$ 的末尾增加一个 <strong>偏置特征</strong>，通常是 $1$。然后，我们需要在每个零向量中增加一个额外的零，使得向量的长度匹配。这使得完整特征向量 $\boldsymbol f(\boldsymbol x,y)$ 的长度为 $(V+1)\times K$。而与该偏置特征相关联的权重可以被想象成一个作用在每个标签上的正或负偏差。例如，如果我们预期大部分的邮件都是垃圾邮件，那么偏置特征的</p>

<p>下节内容：</p>
:ET