I"{!<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-14-贝叶斯回归">Lecture 14 贝叶斯回归</h1>
<h2 id="主要内容">主要内容</h2>
<ul>
  <li><strong>点估计未捕获到的不确定性</strong></li>
  <li><strong>贝叶斯方法保留不确定性</strong></li>
  <li><strong>顺序贝叶斯更新</strong></li>
  <li><strong>共轭先验（Normal-Normal）</strong></li>
  <li><strong>利用后验在测试集上进行贝叶斯预测</strong></li>
</ul>

<h2 id="1-回顾贝叶斯">1. 回顾贝叶斯</h2>
<h3 id="11-训练--优化">1.1 训练 = 优化？</h3>
<p><strong>学习与推断阶段：</strong></p>
<ul>
  <li><strong><span style="color:steelblue">对于分类问题：</span></strong>
    <ul>
      <li>
        <p>建模（以 Logistic 回归为例）</p>

        <script type="math/tex; mode=display">p(y|\boldsymbol x)=\text{sigmoid}(\boldsymbol x'\boldsymbol w)</script>
      </li>
      <li>
        <p>参数拟合数据</p>

        <script type="math/tex; mode=display">\hat{\boldsymbol w}=\mathop{\operatorname{arg\,max}}\limits_{\boldsymbol w}p(\boldsymbol y|\boldsymbol X,\boldsymbol w)p(\boldsymbol w)</script>
      </li>
      <li>
        <p>进行预测</p>

        <script type="math/tex; mode=display">p(y_*|\boldsymbol x_*)=\text{sigmoid}(\boldsymbol x_*'\hat{\boldsymbol w})</script>
      </li>
    </ul>
  </li>
  <li><strong><span style="color:steelblue">对于回归问题：</span></strong>
    <ul>
      <li>
        <p>建模</p>

        <script type="math/tex; mode=display">p(y|\boldsymbol x)=\text{Normal}(\boldsymbol x'\boldsymbol w;\sigma^2)</script>
      </li>
      <li>
        <p>参数拟合数据</p>

        <script type="math/tex; mode=display">\hat{\boldsymbol w}=\mathop{\operatorname{arg\,max}}\limits_{\boldsymbol w}p(\boldsymbol y|\boldsymbol X,\boldsymbol w)p(\boldsymbol w)</script>
      </li>
      <li>
        <p>进行预测</p>

        <script type="math/tex; mode=display">E[y_* ]=\boldsymbol x_*'\hat{\boldsymbol w}</script>
      </li>
    </ul>
  </li>
</ul>

<p><span style="color:red"><script type="math/tex">\hat{\boldsymbol w}</script> 对应于 “点估计”</span></p>

<h3 id="12-贝叶斯替代">1.2 贝叶斯替代</h3>
<p><strong><script type="math/tex">\hat{\boldsymbol w}</script> 并没有什么特别之处……如果我们不只是使用参数的一个估计值呢？</strong></p>
<ul>
  <li><strong><span style="color:steelblue">对于分类问题：</span></strong>
    <ul>
      <li>
        <p>建模</p>

        <script type="math/tex; mode=display">p(y|\boldsymbol x)=\text{sigmoid}(\boldsymbol x'\boldsymbol w)</script>
      </li>
      <li>
        <p>考虑那些可以比较好地拟合数据的 <span style="color:red">可能的参数空间</span></p>

        <script type="math/tex; mode=display">p(\boldsymbol w|\boldsymbol X,\boldsymbol y)</script>
      </li>
      <li>
        <p>进行 <span style="color:red">“期望的”</span> 预测</p>

        <script type="math/tex; mode=display">p(y_*|\boldsymbol x_*)=E_{p(\boldsymbol w|\boldsymbol X,\boldsymbol y)}\left[\text{sigmoid}(\boldsymbol x_*'\boldsymbol w)\right]</script>
      </li>
    </ul>
  </li>
  <li><strong><span style="color:steelblue">对于回归问题：</span></strong>
    <ul>
      <li>
        <p>建模</p>

        <script type="math/tex; mode=display">p(y|\boldsymbol x)=\text{Normal}(\boldsymbol x'\boldsymbol w;\sigma^2)</script>
      </li>
      <li>
        <p>考虑那些可以比较好地拟合数据的 <span style="color:red">可能的参数空间</span></p>

        <script type="math/tex; mode=display">p(\boldsymbol w|\boldsymbol X,\boldsymbol y)</script>
      </li>
      <li>
        <p>进行 <span style="color:red">“期望的”</span> 预测</p>

        <script type="math/tex; mode=display">p(y_*|\boldsymbol x_*)=E_{p(\boldsymbol w|\boldsymbol X,\boldsymbol y)}\left[\text{Normal}(\boldsymbol x_*'\boldsymbol w;\sigma^2)\right]</script>
      </li>
    </ul>
  </li>
</ul>

<h2 id="2-不确定性">2. 不确定性</h2>
<p><strong>如果用于训练的数据集很小，我们很少会完全信任任何从中学习到的模型。我们能否量化这种不确定性，并将其用于预测呢？</strong></p>
<h3 id="21-重新审视回归问题">2.1 重新审视回归问题</h3>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-19-WX20200219-145612%402x.png" width="60%" /></p>

<p><span style="color:red">线性回归：</span> $y=w_0+w_1x$<br />
这里，$y=$ humidity（湿度），$x=$ temperature（温度）</p>

<ul>
  <li>从数据中学习模型
    <ul>
      <li>
        <p>通过选择权重来最小化误差残差</p>

        <script type="math/tex; mode=display">\hat{\boldsymbol w}=(\boldsymbol X'\boldsymbol X)^{-1}\boldsymbol X'\boldsymbol y</script>
      </li>
    </ul>
  </li>
  <li>但是我们对于得到的 $\hat{\boldsymbol w}$ 和预测值有多大的信心？</li>
</ul>

<h3 id="22-我们应该相信点估计-hatboldsymbol-w-吗">2.2 我们应该相信点估计 $\hat{\boldsymbol w}$ 吗？</h3>
<ul>
  <li>我们的学习算法有多稳定？
<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-19-WX20200219-152254%402x.png" width="80%" /><br />
<strong><center><span style="font-size:10pt">两个具有不同噪声水平的数据集以及它们各自对应的似然函数</span></center></strong>
    <center><span style="font-size:10pt">（来源：<span style="font-style:italic">A First Course in Machine Learning (p.81)</span> by Rogers &amp; Girolami）</span></center>

    <ul>
      <li>$\hat{\boldsymbol w}$ 对于噪声高度敏感</li>
      <li>参数估计的不确定性有多少？</li>
      <li>如果目标参数的 <strong>负对数似然（Negative Log Likelihood, NLL）</strong> 的在峰值处越高且窄，说明我们掌握的信息量越大</li>
    </ul>
  </li>
  <li>形式化为 <strong>费雪信息矩阵（Fisher Information Matrix）</strong>
    <ul>
      <li>$E[ 2^{nd} \text{ deriv of NLL}]$<br />
$\cal I$ $=\dfrac{1}{\sigma^2}\boldsymbol X’\boldsymbol X$</li>
    </ul>
  </li>
  <li>衡量关于 $\hat{\boldsymbol w}$ 的目标函数的曲率</li>
</ul>

<h2 id="3-贝叶斯视角">3. 贝叶斯视角</h2>
<p><strong>保留所有的未知因素（例如：参数的不确定性）并对它们进行建模，并且在进行统计推断时利用这些信息。</strong></p>
<h3 id="31-一个贝叶斯人的视角">3.1 一个贝叶斯人的视角</h3>
<ul>
  <li>我们有理由认为 <strong>所有的</strong> 参数对于数据而言都是常数吗？
    <ul>
      <li>对于训练数据拟合更好的权重的概率应该大于其他权重的概率</li>
      <li>利用所有可能的权重进行预测，乘以各自的概率作为缩放系数</li>
    </ul>
  </li>
  <li>这就是 <span style="color:red">贝叶斯推断</span> 背后的思想</li>
</ul>

<h3 id="32-参数的不确定性">3.2 参数的不确定性</h3>
<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-19-WX20200219-191611%402x.png" width="25%" align="right" /></p>

<ul>
  <li>目标函数有很多合理的解
    <ul>
      <li>为什么只选择其中的某一个呢？</li>
    </ul>
  </li>
  <li>考虑 <span style="color:red">所有</span> 可能的参数值背后的原因
    <ul>
      <li>乘以它们的 <span style="color:red">后验概率</span> 作为加权项</li>
    </ul>
  </li>
  <li>更具鲁棒性的预测
    <ul>
      <li>可以更好地避免过拟合，尤其是对于小的训练集而言</li>
      <li>可以得到表达能力更强的模型类别（例如：贝叶斯 Logistic 回归是非线性模型）</li>
    </ul>
  </li>
</ul>

<h2 id="总结">总结</h2>
<ul>
  <li>随机多臂老虎机
    <ul>
      <li>不确定性下的顺序决策</li>
      <li>最简单的 “探索-vs-利用” 的设定</li>
      <li>$(\varepsilon)$-Greedy，UCB 算法</li>
    </ul>
  </li>
  <li>很多应用和变体：
    <ul>
      <li>对抗 MAB：奖励不是随机的，而是任何东西</li>
      <li>上下文 MAB：行动基于上下文特征向量</li>
      <li>强化学习：更加通用的设定</li>
    </ul>
  </li>
</ul>

<p>下节内容：贝叶斯回归</p>
:ET