---
layout:     post   				    # 使用的布局（不需要改）
title:      统计机器学习 12：集成学习   	# 标题 
subtitle:   墨尔本大学 COMP90051 课程笔记 #副标题
date:       2019-11-17 				# 时间
author:     Andy 						# 作者
header-img: img/post-bg-sml.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 统计机器学习
    - 集成学习
    - Bagging
    - Boosting
    - Stacking
---

<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

# Lecture 12 集成学习
## 主要内容
* **集成学习：对冲你的赌注**
* **Bagging 和随机森林**
* **Boosting**
* **Stacking**

## 1. 集成学习
**集成学习：对冲你的赌注**
### 1.1 为什么是 “一个正确” 的模型？
* 到目前为止，我们已经讨论了各个模型，并在孤立 / 竞争中考虑了每个模型
* 我们知道如何评估每个模型的性能（通过准确率、F-measure 等），这使我们能够给一个数据集从 **总体上** 选择出最优的模型
* 但 **总体上** 并没有隐含着每个样本的表现
  * 总体上最优的模型：在某些实例上可能会出错
  * 总体上最差的模型：在某些实例上可能会更好
* <span style="color:red">集成</span> 让我们可以综合使用多个模型

### 1.2 专家小组
* 考虑一个由 3 位专家组成的小组，他们 <span style="color:red">各自独立地</span> 做出分类决策。每个专家决策出错的概率都是 0.3。共识决策由 <span style="color:red">多数投票</span> 产生。

**<span style="color:steelblue">思考：共识决策出错的概率是多少？</span>**  
在共识决策下，出错可能有两种情况：  
a. 3 位专家都出错了  
b. 2 位专家出错了导致最终投票得出错误答案  
所以，将两种情况的概率相加即可：$0.3^3+3\times 0.3^2\times (1-0.3)=0.216$  

* 设定：错误之间互相独立，每一个的概率都是 $p$
* $n$ 个专家各自决策产生的 **错误的数量** 服从 <span style="color:red">二项分布</span> $\color{red}{\text{Binom}(n,p)}$  

  $$\Pr(k)=\begin{pmatrix}n \\ k\end{pmatrix}p^k(1-p)^{n-k}$$  

* 当 <span style="color:red">至少</span> $\color{red}{\lceil n/2 \rceil}$ <span style="color:red">的专家出错</span>（对于 $n$ 为奇数的情况）时，多数投票将会出错  
  $$\Pr(panel\, error)=\sum_{k=\lceil n/2 \rceil}^{n}\begin{pmatrix}n \\ k\end{pmatrix}p^k(1-p)^{n-k}$$  

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-16-WX20200216-201831%402x.png" width="80%">  

### 1.3 组合模型
* 模型组合（又称 <span style="color:red">集成学习</span>）根据给定的训练集构造一个基模型（又称 <span style="color:red">基学习器</span>）的集合，并将输出结果聚合到一个单独的元模型中（<span style="color:red">集成</span>）
  * 分类问题采用（加权）多数投票
  * 回归问题采用（加权）平均
  * 更一般地：*元模型* $=f($*基模型*$)$

* 回忆 **偏差-方差权衡**：  

  $$\Bbb E\left[ l\left(y,\hat f(\boldsymbol x_0)\right) \right]=\left(\Bbb E[y]-\Bbb[\hat f]\right)^2+Var[\hat f]+Var[y]$$  

  $$\text{test error}=(\text{bias})^2+\text{variance}+\text{irreducible error}$$

* 对 $k$ 个 **独立同分布** 的预测进行平均可以减小方差：  

  $$\color{red}{Var\left[\hat f_{avg}\right]=\dfrac{1}{k}Var\left[\hat f\right]}$$

## 2. Bagging
**<span style="color:green">B</span>ootstrap <span style="color:green">agg</span>regat<span style="color:green">ing</span> —— Breiman’94**

### 2.1 Bagging 方法
* **方法：** 通过有放回抽样构建 “近似独立” 的数据集
  * 生成 $k$ 个数据集，每个数据集都包含从 $n$ 条训练数据中通过有放回抽样得到的 $n$ 个样本 —— **Bootstrap 采样**
  * 在每个生成的数据集上构建基分类器
  * 通过投票 / 平均对预测结果进行聚合

例如：
* 原始数据集：  
  $$\{0,1,2,3,4,5,6,7,8,9\}$$
* <span style="color:red">Bootstrap 采样</span>：  
  $$\{7,2,6,7,5,4,8,8,1,0\}$$ —— 未采样 $3,9$  
  $$\{1,3,8,0,3,5,8,0,1,9\}$$ —— 未采样 $2,4,6,7$  
  $$\{2,9,4,2,7,9,3,0,1,0\}$$ —— 未采样 $3,5,6,8$

### 2.2 回忆决策树
<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-16-WX20200216-213133%402x.png" width="80%">  

* 训练标准：每个最终分区的纯度
* 优化：启发式贪婪迭代方法
* 模型复杂度由树的深度定义
* 深树：非常适合特定数据 $\rightarrow$ 高方差，低偏差
* 浅树：粗略近似 $\rightarrow$ 低方差，高偏差

### 2.3 Bagging 的例子：随机森林
* Just bagged trees
* **<span style="color:steelblue">算法描述：</span>**  
  参数：树的数量 $k$，特征数量 $l\le m$  
  1.$\,$初始化一个空的森林  
  2.$\,$对于 $c$ 从 $1$ 到 $k$：  
  $\qquad$ a. 从训练数据创建新的 Bootstrap 采样  
  $\qquad$ b. 从 $m$ 个特征中随机选择出包含 $l$ 个特征的子集  
  $\qquad$ c. 用这 $l$ 个特征在 Bootstrap 样本上训练决策树  
  $\qquad$ d. 将树添加进森林里  
  3.$\,$通过多数投票或者平均来作出预测
* 在许多实际设定下效果非常好


下节内容：集成学习
