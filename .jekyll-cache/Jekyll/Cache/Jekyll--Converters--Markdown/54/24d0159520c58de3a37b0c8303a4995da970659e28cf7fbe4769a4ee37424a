I"l4<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-04-文本分类">Lecture 04 文本分类</h1>

<p>本节课我们将学习 <strong>文本分类（text classification）</strong>。</p>

<p><strong>本节课程大纲</strong></p>
<ul>
  <li>分类的基本原理</li>
  <li>文本分类任务</li>
  <li>分类算法</li>
  <li>评估</li>
</ul>

<h2 id="1-分类的基本原理">1. 分类的基本原理</h2>
<ul>
  <li>输入
    <ul>
      <li>一个文档 $d$
        <ul>
          <li>通常表示为一个特征向量</li>
        </ul>
      </li>
      <li>一个固定的类别输出集合 <script type="math/tex">C=\{c_1,c_2,\dots,c_k\}</script>
        <ul>
          <li>分类的（Categorical），不是连续的（continuous，例如：regression）或者序数的（ordinal，例如：ranking）</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>输出
    <ul>
      <li>一个预测的类别 $c\in C$</li>
    </ul>
  </li>
</ul>

<p>在分类任务中，我们的输入通常是一个文档的集合或者单个的文档，其中包含一些文本数据。另外，我们知道我们的任务所对应的一个封闭集合（closed set），例如对于主题分类任务，我们可能一共有 100 个不同的主题用于分类，这些可能的主题组成了一个封闭的集合，并且该集合里的元素通常是分类标签（categorical labels），而不是用于回归（regression）任务的连续数值或者用于排序的序数型数据（ordinal data）。</p>

<p>而我们希望输出一个关于文档 $d$ 的预测类别 $c$，它应该是来自封闭集合 $C$ 中的一个元素。在一些其他类型的分类任务变体中，我们想要预测的可能不是一个类别，而是多个类别，我们称之为 <strong>多标签分类（multi-label classification）</strong>，但是今天我们不会讨论它。本节课中，我们假设在我们要处理的应用中，正确的标签类别只有一个。</p>

<h2 id="2-文本分类任务">2. 文本分类任务</h2>
<p>有很多不同种类的文本分类任务，这节课我们主要通过一些例子介绍以下几种：</p>
<ul>
  <li>
    <p><strong>主题分类（Topic classification）</strong><br />
关于试图理解给定文档的主题是什么，例如：我们可能想知道一篇给定的文章是关于体育的还是国际新闻的。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>情感分析（Sentiment analysis）</strong><br />
尝试分析作者对于某种产品或者一些其他事情的情感，经常用于评论领域，例如：影评、购物点评、产品测评等。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>作者身份识别（Authorship attribution）</strong><br />
目标是试图发现某段文本的原作者是谁，例如：司法语言学、抄袭检测等。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>母语识别（Native-language identification）</strong><br />
类似于作者身份识别，我们也是希望通过一段文本推测出作者相关的一些信息，不同的是，在母语识别中，我们关心的不是作者的确切身份，而是其使用的母语是什么。例如：非英语母语者在进行英文写作时，往往会倾向于采用一种不同于英语母语者的风格，我们可能希望知道其母语是什么。母语识别可以用于教育领域，因为它可以帮助教师发现一些特定学生群体在用非母语写作时可能会犯的一些共同错误。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>自动事实检测（Automatic fact-checking）</strong><br />
自动事实检测是一个目前需求非常迫切的领域，同时也是一个非常困难的领域。其目的是帮助人们识别社交网络媒体上的一些虚假新闻和信息。</p>
  </li>
</ul>

<p>另外，请注意我们的 <strong>输入不一定是完整的 “文本”</strong>：尽管我们一直说输入是一个文档，但这并不意味着它总是像一篇新闻这种相对比较长的文档，它也可以是像一条推特这种非常短的文本（例如：基于推特的情感极性分析）。当我们谈到 “文档” 或者 “文本” 时，我们并不能假设输入的内容很长，它很有可能只有一句话，甚至可能只是一些 emoji 表情符号。</p>

<h3 id="21-主题分类">2.1 主题分类</h3>
<ul>
  <li>
    <p><strong>应用场景</strong>：图书馆学（library science）和信息检索（information retrieval）<br />
例子：想象你有一个在线图书馆，你试图整理你拥有的这些电子书和数字文档中的知识，如果有一种方法可以帮助你对这些成百上千的文档自动进行分类，那么用户就可以更轻松地在里面浏览和搜索信息。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>标签类别</strong>：不同的主题类别（topic categories）<br />
例子：媒体出版物中可能会有很多不同的主题分类，像 “工作”、“国际新闻” 等等。具体分类类别取决于你的数据来自的领域。</p>

    <p><br /></p>
  </li>
  <li><strong>特征</strong>：
    <ul>
      <li><strong>词袋模型（bag of words, BOW）</strong><br />
词袋模型表示是一个很好的选择，通常 unigram 已经足够了。另外，我们可能希望移除一些功能词和停用词，它们并没有包含太多与内容相关的信息。因为在主题分类任务中，我们希望提取到的是一些与内容相关的单词，这些单词可以帮助我们确定文本的主题。</li>
      <li><strong>更长的 N-grams 模型用于词组（phrases）</strong><br />
另外，对于词组（phrases），我们有时也会使用一些更长的 n-grams 模型（例如：bigrams、trigrams），所以我们也可以有 a bag of bigrams 或者 a bag of trigrams。</li>
    </ul>

    <p><br /></p>
  </li>
  <li><strong>语料库的例子</strong>：
    <ul>
      <li>Reuters news corpus（RCV1，路透社新闻语料库，请参阅 NLTK 示例）</li>
      <li>Pubmed abstracts（一个提供生物医学方面的论文搜索和摘要的数据库）</li>
      <li>Tweets with hashtags（带有话题标签的推文）</li>
    </ul>
  </li>
</ul>

<h3 id="22-主题分类的例子">2.2 主题分类的例子</h3>
<p>请问以下来自路透社新闻语录中的文本的主题是 <strong>收购（acquisitions）</strong> 还是 <strong>收益（earnings）</strong>？</p>

<blockquote>
  <p>LIEBERT CORP APPROVES MERGER<br />
Liebert Corp said its shareholders approved the merger of a wholly-owned subsidiary of Emerson Electric Co. Under the terms of the merger, each Liebert shareholder will receive .3322 shares of Emerson stock for each Liebert share.</p>
</blockquote>

<p>这段文本中提到了 “<em>股东（shareholders）</em>”、“<em>合并（merge）</em>”、“<em>子公司（subsidiary）</em>”、“<em>分配股票（share stock）</em>” 这些词，所以我们可以判断这段文本的主题应该是 <strong>收购（acquisitions）</strong>。</p>

<h3 id="23-情感分析">2.3 情感分析</h3>
<ul>
  <li>
    <p><strong>应用场景</strong>：意见挖掘（opinion mining）、商业分析（business analytics）<br />
例如：你所在的公司最近发布了一个新产品，你希望获得一些用户反馈。如今，社交媒体是一个用来挖掘用户意见的好地方，这些从网络渠道挖掘到的用户反馈将有助于产品的改善。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>标签类别</strong>：正面（Positive）/ 负面（Negative）/ 中性（Neutral）<br />
通常，情感分析的结果可以分为正面和负面两种情况，但是有时我们也会考虑中性的情况。</p>

    <p><br /></p>
  </li>
  <li><strong>特征</strong>：
    <ul>
      <li>
        <p><strong>N-grams</strong><br />
这里我们不用词袋模型，而是采用 n-grams 特征。原因是在之前的主题分类任务中，我们并不关心单词之间的顺序；但是在情感分析任务中，单词之间的顺序非常重要。例如：我们的句子中有一个非常正面的词 “$\textit{happy}$”，假如我们像之前词袋模型中一样丢弃单词之间的顺序信息，那么预测的效果将不会太好。</p>
      </li>
      <li>
        <p><strong>极性词典（Polarity lexicons）</strong><br />
极限词典本质上是一个包含了一堆正面极性和负面极性的单词的字典。通常是由人们手工创建的，它的精度很高，但是覆盖范围很小，很适用于通过 bootstrap 的方式来提升我们算法的表现。</p>
      </li>
    </ul>

    <p><br /></p>
  </li>
  <li><strong>语料库的例子</strong>：
    <ul>
      <li>Polarity movie review dataset (NLTK 中的极性影评数据集)</li>
      <li>SEMEVAL Twitter polarity datasets（基于推特的情感极性分析数据集）</li>
    </ul>
  </li>
</ul>

<h3 id="24-情感分析的例子">2.4 情感分析的例子</h3>
<p>请问以下来自 SEMEVAL Twitter polarity datasets 中的推文的 <strong>极性（+/-）</strong> 是什么?</p>

<blockquote>
  <p>anyone having problems with Windows 10? may be coincidental but since i downloaded, my WiFi keeps dropping out. Itunes had a malfunction</p>
</blockquote>

<p>可以看到，该用户表示自己的 Windows 10 总是出现 WiFi 掉线的问题。显然，对于 Windows 10 来说，这不是什么积极的评价。所以我们可以判断这段文本的情感极性应该是 <strong>负面的（Negative）</strong>。</p>

<hr />
<hr />

<h2 id="6-总结">6. 总结</h2>

<ul>
  <li>
    <p>N-gram 模型在捕捉语言的可预测性方面是一种简单且高效的方法。<br />
模型的构建很容易：我们只需要一个大的语料库，并且对单词和上下文进行计数即可。</p>
  </li>
  <li>
    <p>信息可以通过无监督的方式推导得出，可以扩展到大型语料库。</p>
  </li>
  <li>
    <p>由于稀疏性的存在，需要进行平滑处理才能保证有效性。<br />
我们需要一些工程上的技巧处理稀疏性问题，例如：smoothing、back-off、interpolation 等。</p>
  </li>
</ul>

<p>虽然 n-gram 模型非常简单，但是它在实践中的效果非常好。所以，在构建语言模型时，我们通常会选择将 n-gram 模型作为 baseline，尽管目前有很多模型都采用了深度学习。</p>

<h2 id="7-思考">7. 思考</h2>

<p><strong><span style="color:steelblue">思考：</span></strong> Interpolation、Interpolated Kneser-Ney 和 Kneser-Ney 之间有什么区别？我们应当如何判断应该采用哪种方法？</p>

<p>首先，我们应该明确一点：Interpolated（插值）、Smoothing（平滑）和 Backoff（回退）都是用来解决数据稀疏问题（sparsity）的方法。我们在这节课中讨论的前 3 种平滑方法（拉普拉斯、“加 k” 和 Lidstone）都是在 <strong>和原先的 N-gram 模型相同的阶数</strong> 内重新分配概率，将概率质量从常见情况向罕见情况进行偏移。</p>

<p>Interpolation 和 Backoff 都是通过 <strong>结合不同阶数的 N-gram 模型</strong> 来解决这个问题。对于 Backoff 而言，如果高阶 higher-gram 的计数为 $0$，那么它将完全落回低阶 lower-gram；而 Interpolation 则是通过将我们所有的 N-gram 模型加权求和来将它们结合起来。</p>

<p>现在，当我们采用低阶模型时又会带来一个新的问题。例如，对于单词 “$\textit{Old}$” 和 “$\textit{Zealand}$”，很可能它们的 bi-gram “$\textit{Old Zealand}$” 计数为 $0$，所以我们需要依赖 unigram 模型提供的概率。想象一下，如果单词 “$\textit{Zealand}$” 具有一个非常高的 unigram 概率，那么对于这两个词的 bi-gram，我们还是可以得到一个相对较高的共现概率，而这不是我们希望看到的。</p>

<p>Kneser-Ney Smoothing 中引入了所谓 <strong>延续计数（continuation count）</strong> 的概念。因为在大多数情况下，单词 “$\textit{Zealand}$” 只出现在上下文单词 “$\textit{New}$” 的后面，所以对于单词 “$\textit{Zealand}$” 出现在上下文单词 “$\textit{Old}$” 后面这种情况（即 bi-gram “$\textit{Old Zealand}$”）的延续计数会非常低。到这里，我们通过 <strong>在不同上下文中的频率计数</strong> 解决了上述例子中的问题。</p>

<p>回到原问题中提到的哪种方法更好，我们可以在 Backoff 或者 Interpolation 二者中选择一种来使用 Kneser-Ney Smoothing。通常来说，Interpolation 可能更合适，因为这种方式更灵活（因为我们考虑了所有阶数的 N-gram 模型）。</p>

<h2 id="8-扩展阅读">8. 扩展阅读</h2>
<ul>
  <li><em><a href="https://canvas.lms.unimelb.edu.au/courses/17601/files/2586500/download">Natural Language Processing, Draft 15/10/18</a></em>, by Eisenstein
    <ul>
      <li>Chapter 6 (skip 6.3)</li>
    </ul>
  </li>
</ul>

<p>下节内容：文本分类</p>

:ET