I"Q<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-01-导论">Lecture 01 导论</h1>
<h2 id="1-概览">1. 概览</h2>
<ul>
  <li><strong>线性（回归）模型</strong> 可以说是几乎所有统计应用中使用的最重要的统计模型。</li>
  <li>
    <p>一个线性模型可以由下面的回归方程定义：</p>

    <script type="math/tex; mode=display">% <![CDATA[
\begin{align}
Y &= \beta_0+\beta_1 X_1+\cdots+\beta_{p-1} X_{p-1}+\epsilon,\qquad 或者 \\\\
Y &= \mu+\varepsilon，\;\; 其中\;\; \mu=E(Y)=\beta_0+\beta_1 X_1+\cdots+\beta_{p-1} X_{p-1}
\end{align} %]]></script>

    <p>其中，</p>
    <ul>
      <li>$Y$：响应变量（也称 “结果变量” 或者 “因变量”）；</li>
      <li>$X_1,\cdots,X_{p-1}$：协变量（也称 “解释变量”、“预测变量” 或者 “自变量”）；</li>
      <li>$\varepsilon$：随机误差，具有均值 $0$ 和未知的常数方差 $\sigma^2$；</li>
      <li>$\beta_0,\beta_1,\cdots,\beta_{p-1}$：未知的回归参数，需要基于观测数据对其进行估计。</li>
    </ul>

    <p><br /></p>

    <p><strong>注意：</strong></p>
    <ul>
      <li>这里我们假设随机误差 $\varepsilon$ 的均值为 $0$ 可以从下面两个角度理解：
        <ul>
          <li>直观上：假如其均值不为 $0$，说明它影响着 $Y$ 的均值（或者说预测值），进而说明随机误差项中仍然存在可以影响 $Y$ 的因素，比如遗漏的解释变量，因此模型仍有改进的必要。</li>
          <li>形式上：在不假设误差项 $0$ 均值（但是模型需要引入常数项 $\beta_0$）的情况下，我们会遇到模型识别的问题，此时我们无法区分常数项和随机误差项的均值。所以我们要么不引入常数项 $\beta_0$，要么假设误差项均值为 $0$。</li>
        </ul>
      </li>
      <li>而假设随机误差的方差 $\sigma^2$ 为未知常数可以这样理解：<br />
由于存在随机变化，因此我们很难确定数据集中的所有数据是否具有相同的质量。然而，大多数建模过程在使用这些数据来估计模型中的未知参数时都会平等地对待所有数据。大多数方法还使用数据中随机变化量的单个估计值来计算预测和校准不确定性。以相同的方式处理所有数据也会得到更简单、更易于使用的模型。反之，如果事实证明数据的质量并不均等，那么像这样处理数据的决定也会对结果模型的质量产生负面影响。</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>
    <p>给定 $n$ 个观测数据点 $(Y,X_1,\cdots,X_{p-1})$，上面的回归方程可以写成向量 / 矩阵的形式：</p>

    <script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mathbf y &= X\boldsymbol \beta + \boldsymbol \varepsilon,\qquad 或者\\\\
\mathbf y &= \boldsymbol \mu + \boldsymbol \varepsilon,\;\; 其中\;\; \boldsymbol \mu=E(\mathbf y)=X\boldsymbol \beta
\end{align} %]]></script>

    <p>其中，$\boldsymbol \mu=(\mu_1,\dots,\mu_n)^{\top},\;\boldsymbol \varepsilon=(\varepsilon_1,\dots,\varepsilon_n)^{\top},$</p>

    <script type="math/tex; mode=display">% <![CDATA[
\mathbf y=\begin{bmatrix} y_1 \\ \vdots \\ y_i \\ \vdots \\ y_n \end{bmatrix}_{\,n\times 1},\quad X=\begin{bmatrix}1 & x_{11} & \cdots & x_{1,p-1} \\ \vdots & \vdots &  & \vdots\\ 1 & x_{i1} & \cdots & x_{i,p-1} \\ \vdots & \vdots &  & \vdots\\ 1 & x_{n1} & \cdots & x_{n,p-1} \end{bmatrix}_{\,n\times p},\quad \boldsymbol \beta=\begin{bmatrix} \beta_0 \\ \beta_1  \\ \vdots \\ \beta_{p-1} \end{bmatrix}_{\,p\times 1} %]]></script>
  </li>
  <li>
    <p>在一个线性模型中，$y_1,\dots,y_n$ 被假设为彼此之间相互独立，而 $X$ 被假设为已经确定的而非随机的。</p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>在本课程中，我们将从以下 4 个方面对线性模型进行扩展：
    <ul>
      <li>$Y$ 的分布从正态扩展到一个指数族成员，引出广义线性模型（GLM）；</li>
      <li>假设 $y_1,\dots,y_n$ 之间存在依赖关系，引出多元广义线性模型（multivariate GLM）；</li>
      <li>$\boldsymbol \mu=E(\mathbf y)$ 可能是 $X$ 和 $\boldsymbol \beta$ 的一个非参数函数，引出非参数回归模型（nonparametric regression models）；</li>
    </ul>
  </li>
</ul>

<p>下节内容：</p>

:ET