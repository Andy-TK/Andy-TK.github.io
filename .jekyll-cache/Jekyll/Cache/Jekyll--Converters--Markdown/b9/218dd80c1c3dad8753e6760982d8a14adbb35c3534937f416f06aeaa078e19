I"Y<<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-03-搜索算法-2">Lecture 03 搜索算法 (2)</h1>

<p>上周我们讨论了一些盲目搜索算法，我们可以利用这些算法来寻找一条从起始结点到目标结点的路径。另外，我们也简单地提到了启发式搜索算法在大部分任务中要比盲目搜索算法表现更好。</p>

<h2 id="3-启发函数">3. 启发函数</h2>
<h3 id="31-系统算法和局部算法">3.1 系统算法和局部算法</h3>
<p>$\to$ 在经典规划领域，启发式搜索算法是最常见，并且几乎也是最成功的搜索算法。</p>

<p><strong>系统启发式搜索算法</strong>：</p>
<ul>
  <li><span style="color:blue">贪婪最佳优先搜索（Greedy best-ﬁrst search）</span><br />
<span style="color:red">$\to$ 满意规划（satisﬁcing planning）中最流行的 3 种算法之一。</span></li>
  <li><span style="color:blue">加权 $\rm{A}^*$<br />
<span style="color:red">$\to$ 满意规划（satisﬁcing planning）中最流行的 3 种算法之一。</span></span></li>
  <li><span style="color:blue">$\rm{A}^*$</span><br />
<span style="color:red">$\to$ 最优规划（optimal planning）中最流行的算法。</span>（在满意规划中很少使用。）</li>
  <li>还有很多，诸如 $\rm{IDA}^*$、深度优先分支定界搜索（depth-ﬁrst branch-and-bound search）、广度优先启发式搜索（breadth-ﬁrst heuristic search）等等。</li>
</ul>

<p><strong>局部启发式搜索算法</strong>：</p>
<ul>
  <li><span style="color:blue">爬山算法（Hill-climbing）</span></li>
  <li><span style="color:blue">增强爬山算法（Enforced hill-climbing）</span><br />
<span style="color:red">$\to$ 满意规划（satisﬁcing planning）中最流行的 3 种算法之一。</span></li>
  <li>还有很多，诸如 波束搜索（Beam search）、禁忌搜索（tabu search）、遗传算法（genetic algorithms）、模拟退火（simulated annealing）等等。</li>
</ul>

<h3 id="32-基本思想">3.2 基本思想</h3>
<p>本质上，启发式搜索是一种对于从某个状态到目标状态所需代价的估计。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-19-WX20200319-212829%402x.png" width="70%" /></p>

<p>$\to$ <strong>启发函数（Heuristic function）</strong> $h$ 估计了到达目标的一条最优路径的代价；搜索会倾向于探索具有较小 $h$ 的状态。</p>

<h3 id="33-启发函数">3.3 启发函数</h3>
<p>启发式搜索需要一个启发函数来估计剩余代价：</p>

<p><strong>定义（<span style="color:blue">启发函数</span>）</strong>：令 $\Pi$ 表示一个状态空间为 $\Theta_{\Pi}$ 的规划任务。$\Pi$ 的一个 <span style="color:blue">启发函数</span>（简称 <span style="color:blue">启发</span>）是一个函数 <span style="color:blue"><script type="math/tex">h:S\to \mathbb R_0^+ \cup \{\infty\}</script></span>。对于某个状态 $s$，其对应的启发函数的值 <span style="color:blue">$h(s)$</span> 被称为该状态的 <span style="color:blue">启发值（heuristic value）</span>，或者 <span style="color:blue">$h$ 值</span>。</p>

<p>本质上，启发函数是一种映射：它将状态空间 $S$ 映射到一个包含 $0$、正实数以及 $\infty$ 的一个空间。</p>

<p><strong>定义（<span style="color:blue">剩余代价，$h^*$</span>）</strong>：令 $\Pi$ 表示一个状态空间为 $\Theta_{\Pi}$ 的规划任务。对于一个状态 $s\in S$，该状态的 <span style="color:blue">剩余代价（remaining cost）</span> 为对于 $s$ 而言的一个最优规划的代价；或者如果对于 $s$ 不存在这种规划，则其对应的剩余代价为 $\infty$。对于任务 $\Pi$，它的 <span style="color:blue">完美启发（perfect heuristic）</span>，记为 <span style="color:blue">$h^*$</span>，为每一个 $s\in S$ 分配的启发值都等于各自的剩余代价。</p>

<p>如果一个启发函数是完美启发 $h^*$，这意味着它可以准确地估计从当前状态到目标状态的代价。</p>

<h3 id="34-关于启发函数的讨论">3.4 关于启发函数的讨论</h3>
<p><strong>前面提到的 “估计剩余代价” 是什么意思？</strong></p>
<ul>
  <li>对于很多启发式搜索算法，$h$ 不需要具备任何能够让算法 “工作”（即正确或者完备）的性质。<br />
$\to$ $h$ 可以是任何将状态映射到数字的函数。</li>
  <li>搜索 <span style="color:blue">性能</span> 关键取决于 “$h$ 对于 $h^*$ 的反映程度有多好”。<br />
$\to$ 这可以被非正式地称为 $h$ 的 <span style="color:blue">信息性（informedness）</span>或者 <span style="color:blue">量（quality）</span> 。</li>
  <li>对于某些搜索算法，例如 $\rm{A}^*$，我们可以证明 $h$ 的正式的量性质（formal quality properties）和搜索效率（主要是结点扩展的次数）之间的关系。</li>
  <li>对于其他的搜索算法，“它在实践中效果很好” 通常是一种很好的分析方法。</li>
</ul>

<p><span style="color:blue">$\to$ 我们将详细分析规划中的一个特别重要的启发函数 $h^+$ 的近似值。</span></p>

<p>“搜索性能的关键取决于 $h$ 的信息性。”</p>

<p><span style="color:red">那么，搜索性能的关键还取决于 $h$ 的其他性质吗？</span></p>

<p>“还有计算 $h$ 时的额外计算开销。”</p>

<p><strong>极端情况</strong>：</p>
<ul>
  <li>$h=h^*$：完美的信息性；计算它 $=$ 在第一步就解决规划问题。</li>
  <li>$h=0$：没有任何信息；可以在常数项时间内被 “计算” 出来。</li>
</ul>

<p>$\to$ 成功的启发式搜索需要在 $h$ 的信息性和计算它所产生的额外计算开销之间寻找一个好的平衡点。</p>

<p><span style="color:red">$\to$ 这就是有关搜索的全部内容的本质。</span>设计方法，以合理的计算成本得出良好的估计。</p>

<h3 id="35-启发函数的性质">3.5 启发函数的性质</h3>
<p><strong>定义（<span style="color:blue">安全性/目标察觉性/可采纳性/一致性</span>）</strong>：令 $\Pi$ 表示一个状态空间 $\Theta_{\Pi}=(S,L,c,T,I,S^G)$ 的规划任务，令 $h$ 为 $\Pi$ 的一个启发。那么该启发被认为具有：</p>

<ul>
  <li>
    <p><span style="color:blue">安全性（safe）</span>：如果对于所有满足 $h(s)=\infty$ 的 $s\in S$，都有 $h^*(s)=\infty$；</p>

    <p>如果启发函数认为当前状态 $s$ 到达目标状态的代价为 $\infty$，即不存在一条到达目标状态的路径，那么 $h^*(s)=\infty$ 则保证了事实上确实不存在这样一条路径。</p>
  </li>
  <li>
    <p><span style="color:blue">目标察觉性（goal-aware）</span>：如果对于所有的目标状态 $s\in S^G$，都有 $h(s)=0$；</p>

    <p>如果启发函数认为当前状态到目标状态的代价为 $0$，那么当前状态应该已经是目标状态了。</p>
  </li>
  <li>
    <p><span style="color:blue">可采纳性（admissible）</span>：如果对于所有的 $s\in S$，都有 $h(s)\le h^*(s)$；</p>

    <p>启发函数估计的从当前状态到目标状态的代价总是小于或者等于实际到达目标状态所需的代价。这意味着我们总是希望启发函数是乐观的，总是低估到达目标状态所需的代价。</p>
  </li>
  <li>
    <p><span style="color:blue">一致性（consistent）</span>：如果对于所有的状态转移 $s\xrightarrow{\,a\,} s’$，都有 $h(s)\le h(s’)+c(a)$。</p>

    <p>如果一致性条件成立，那么意味着任何行动 $a$ 产生的状态转移所导致的启发值的减小量 $h(s)-h(s’)$ 都不会超过这次行动的代价 $c(a)$</p>
  </li>
</ul>

<p><span style="color:red">$\to$ 彼此之间的关系？</span></p>

<p><strong>命题</strong>：令 $\Pi$ 表示一个状态空间为 $\Theta_{\Pi}=(S,L,c,T,I,S^G)$ 的规划任务，令 $h$ 为 $\Pi$ 的一个启发。如果 $h$ 具有一致性和目标察觉性，那么 $h$ 具有可采纳性。如果 $h$ 具有可采纳性，那么 $h$ 具有目标察觉性和安全性。除此以外，不存在任何其他关系。</p>

<p><strong>证明</strong>：<span style="color:orange">$\to$ 作为练习</span></p>

<h2 id="4-系统启发式搜索算法">4. 系统启发式搜索算法</h2>

<h3 id="41-贪婪最佳优先搜索greedy-best-first-search">4.1 贪婪最佳优先搜索（Greedy Best-First Search）</h3>
<p>我们已经知道了什么是启发函数，接下来我们可能希望利用一些结合了启发函数的搜索算法来更高效地找出到达目标状态的路径。其中最常见的一算法就是贪婪最佳优先搜索。</p>

<p>在介绍算法的伪代码之前，我们先看一段视频：</p>

<video width="705" controls="">
  <source src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-20-GBFS.mp4" type="video/mp4" />
</video>

<p>可以看到，贪婪最佳优先搜索算法真正所做的是贪婪地试图寻找最优路径，因此它总是优先扩展那些启发函数认为距离目标最近的结点，而并不在意达到目标需要的总的代价。所以，图中那些黄色的方块代表边缘，搜索算法所做的是寻找启发函数认为距离目标最近的路径，在这里，我们可能将启发函数设置为估计距离目标的曼哈顿距离（Manhattan Distance），并且不考虑迷宫内那些墙的存在。可以看到，算法开始向目标所在方位扩展结点，但是在距离目标较近的地方连续碰壁之后，算法会退回原先的地方，重新朝另一个方向再次搜索，并且最终找到了目标。</p>

<p>所以，贪婪优先搜索背后的主要思想是，我们可以计算问题中的每个结点的启发值，然后简单地基于启发值进一步扩展那些距离目标最近的结点，从而找到到达目标状态的路径。</p>

<p><strong>贪婪最佳优先搜索算法（包含重复检测）伪代码描述</strong>：</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-20-WX20200320-141446%402x.png" /></p>

<p>我们先初始化一个优先队列，队列优先级按照启发值 $h(\rm{state}(\sigma))$ 给出（$h(\rm{state}(\sigma))$ 越小，优先级越高），所以当我们从队列中 pop 出一个元素时，我们将得到一个基于启发值估计的距离目标最近的结点。初始时，我们将根结点插入优先队列。同时我们初始化一个空的闭合列表。只要优先队列中还存在结点时，我们就将其中距离目标最近的结点 pop 出队列。将它们存储在闭合列表中，确保我们清除重复，在探索时将重复结点一起探索。如果我们找到了目标状态，那么返回解。否则，我们将对当前结点的所有邻接结点进行扩展，将它们加入优先队列，然后重复先前的步骤，直到找到距离目标状态最近的结点。</p>

<p><strong>贪婪最佳优先搜索算法评估</strong>：</p>
<ul>
  <li><strong>性质</strong>：
    <ul>
      <li><span style="color:red">完整性</span> 可以保证吗？<br />
可以，对于具备安全性的启发。（并且重复检测可以避免图中存在环 的情况）</li>
      <li>
        <p><span style="color:red">最优性</span> 可以保证吗？<br />
不能，即使对于完美启发也是。例如：起始状态到目标状态之间存在两种状态转移方式，一个需要付出一百万元的代价，而另一个是免费的。没有什么可以防止贪婪最佳优先搜索选择更差的那个。</p>

        <video width="620" controls="">
  <source src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-20-GBFS1.mp4" type="video/mp4" />
</video>

        <p>可以看到，刚开始，算法探索了左边和上边两个方向，因为它们到目标的距离是一样的。但是当算法探索到上方接近边界处时，发现了右边方向有一条接近目标的路径，最终找到了视频中所示的路径，但是，这条路径显然不是最优的。可以看到，从左边出发然后向下再向右的方向还存在一条更短的路径，但是贪婪最佳优先搜索算法并没有给出。</p>
      </li>
      <li>在 $h$ 的所有严格单调变换下不变（例如，使用一个正的常数缩放或着增加一个常数）。</li>
    </ul>
  </li>
  <li><strong>实现</strong>：
    <ul>
      <li>优先队列：例如一个 <span style="color:blue">最小堆（min heap）</span></li>
      <li>“检查重复”：可能已经在 “展开状态” 中探索过了；之所以在 “找到当前最优状态”（即将优先队列中距离目标最近的结点 pop 出队列）之后进行此操作只是为了更清楚地指出与 $\rm{A}^*$ 算法的关系。</li>
    </ul>
  </li>
</ul>

<h3 id="42-rma-算法">4.2 $\rm{A}^*$ 算法</h3>

<p>我们已经介绍了贪婪最佳优先搜索算法，它是满意规划中最常见的搜索算法之一，它旨在找到一个存在的规划，而不关心结果是否是最优的。但是涉及最优规划问题，最常见的还是 $\rm{A}^*$ 算法。</p>

<p>$\rm{A}^*$ 算法的思想是：相比优先扩展距离目标状态最近的结点（即贪婪最佳优先搜索中具有最小启发值 $h(\rm{state}(\sigma))$ 的结点），我们增加一项，用 $g(\mathrm{state(\sigma)})+h(\mathrm{state}(\sigma))$ 来衡量优先级。其中，启发值 $h(\rm{state}(\sigma))$ 估计了当前结点到达目标结点的代价，而 $g(\mathrm{state(\sigma)})$ 则代表了从起始结点到达当前结点的代价，二者之和越小，则对应的结点扩展优先级越高。</p>

<p>在介绍 $\rm{A}^*$ 算法的伪代码之前，我们先看一个例子：</p>
<ul>
  <li>
    <p>我们从初始结点 $I$ 开始，它的 $g(\mathrm{state}(I))=0$ 因为是起始结点，启发值 $h(\mathrm{state}(I))=3$。</p>

    <p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-21-WX20200321-113104%402x.png" width="80%" /></p>
  </li>
  <li>
    <p>我们对结点 $I$ 进行扩展，得到两个后继结点，它们对应的 $g(\mathrm{state(\sigma)})+h(\mathrm{state}(\sigma))$ 分别为 $(1+2)$ 和 $(1+3)$。</p>

    <p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-21-WX20200321-113612%402x.png" width="80%" /></p>
  </li>
  <li>
    <p>我们选择 $(1+2)$ 对应的结点继续进行扩展，得到 $(2+6)$ 和 $(2+7)$ 对应的两个后继结点。</p>

    <p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-21-WX20200321-114450%402x.png" width="80%" /></p>
  </li>
  <li>
    <p>此时，我们的优先队列中一共存在 3 个结点：$(1+3)$、$(2+6)$ 和 $(2+7)$，因此，接下来我们选择 $(1+3)$ 对应的结点进行扩展。</p>
  </li>
</ul>

<p><strong>$\rm{A}^*$ 算法（包含重复检测和重新开放）伪代码描述</strong>：</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-03-20-WX20200321-002017%402x.png" /></p>

<p>下节内容：搜索算法 (2)</p>
:ET