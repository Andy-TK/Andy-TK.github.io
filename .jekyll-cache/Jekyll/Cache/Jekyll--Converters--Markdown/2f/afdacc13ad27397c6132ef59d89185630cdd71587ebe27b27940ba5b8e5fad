I"<h1 id="lecture-07-非线性模型">Lecture 07 非线性模型</h1>

<p><strong>参考教材</strong>：</p>

<ul>
  <li><em>Gareth, J., Daniela, W., Trevor, H., &amp; Robert, T. (2013). An intruduction to statistical learning: with applications in R. Spinger.</em></li>
  <li><em>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Spinger Science &amp; Business Media.</em></li>
</ul>

<h2 id="1-引言">1. 引言</h2>

<p>目前为止，我们讨论的内容大多集中于线性模型。相比于其他模型而言，线性模型更易于描述、实现简单、解释性和推断理论都相对成熟。然而，我们也不能回避标准线性回归模型在预测上明显不足的问题。这是因为模型的线性假设通常只是对真实函数的一种近似，有时这种近似效果并不理想。</p>

<p>上节课中，我们介绍了一些用于提升线性回归模型预测效果的模型，例如：基于最小二乘的岭回归、Lasso、PCR 和 PLS。这些模型在降低线性模型复杂度的同时也降低了估计的方差。但事实上，线性模型的形式仍未改变。</p>

<p>本节课中，我们将介绍一些非线性模型，它们在保证良好的可解释性的前提下，通过放松线性假设对原始线性模进行简单推广，例如：</p>

<ul>
  <li>
    <p><strong>多项式回归 (Polynomial regression)</strong>：用原始预测变量的幂作为新的预测变量以替代原始变量。例如：一个三次回归模型包含三个预测变量 $X,X^2,X^3$。这是一种简单实用的表达数据非线性关系的模型。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>阶梯函数 (Step functions)</strong>：将某个预测变量的取值空间分割成 $K$ 个不同区域，以此来生成一个新的定性变量，分段拟合一个常量函数。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>回归样条 (Regression spline)</strong>：该方法在形式上比多项式回归和阶梯拟合方法更灵活，实际上回归样条可以视为前两类方法的推广。首先将 $X$ 的取值范围分割成 $K$ 个区域，在每个区域上分别独立拟合一个多项式函数。然而，通常会对这些多项式函数进行一些限制以保证在区域边界或 <strong>结点 (knots)</strong> 处的连接是光滑的。只要将 $X$ 的取值区间划分为足够多的区域，此方法就能够产生灵活度很高的拟合。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>光滑样条 (Smoothing splines)</strong>：与回归样条类似，但是产生机制略有不同，一般是通过最小化一个带光滑惩罚项的残差平方和的式子来得到光滑样条的结果。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>局部回归 (Local regression)</strong>：与样条方法类似，但是存在一个重大差别：局部回归中的区域之间是允许重叠的，并且这种重叠将以一种非常光滑的方式完成。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>广义可加模型 (Generalized additive models)</strong>：实际上是将上述模型推广到多个预测变量的情况。</p>
  </li>
</ul>

<p>上述方法都具有很高的灵活性，并且不会丢失线性模型的简单性和可解释性。</p>

<h2 id="2-多项式回归">2. 多项式回归</h2>

<p>为了体现响应变量和预测变量之间的非线性关系，将线性模型推广的最自然的方法是将标准线性模型替换为一个多项式函数：</p>

<script type="math/tex; mode=display">y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \beta_3 x_i^3 + \dots + \beta_d x_i^d + \epsilon_i</script>

<p>其中，$\epsilon_i$ 是误差项。这种方法称为 <strong>多项式回归</strong>。对于阶数比较大的 $d$，多项式回归将呈现明显的非线性曲线。</p>

<p>注意到其本质上可视为预测变量 $x_i,x_i^2,x_i^3,\dots,x_i^d$ 的标准线性模型，因此用最小二乘回归的方法就能得到其系数的估计。对多项式阶数 $d$ 的选择不宜过大，一般不大于 $3$ 或者 $4$，这是因为 $d$ 越大，多项式曲线就会变得过于灵活，以至于出现一些奇怪的形状，尤其是在 $X$ 变量的边界附近。</p>

<p>图 1 的左图是 <code class="language-plaintext highlighter-rouge">Wage</code> 数据集中的 <code class="language-plaintext highlighter-rouge">wage</code> 变量关于 <code class="language-plaintext highlighter-rouge">age</code> 变量的散点图，其中包含了居住在美国亚特兰大中部地区男性的收入和人口信息。图中蓝色实线是使用最小二乘法拟合的 $4$ 阶多项式回归的结果。尽管表面上看，这个模型与其他线性回归模型并无明显差异，但每个变量的系数不再是模型关注的重点。相反，通过观察 <code class="language-plaintext highlighter-rouge">age</code> 在 $18$ 岁到 $80$ 岁之间的 $62$ 个观测值的函数拟合结果，可以帮助我们更好地理解 <code class="language-plaintext highlighter-rouge">age</code> 和 <code class="language-plaintext highlighter-rouge">wage</code> 的关系。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-09-WX20201110-003200%402x.png" width="80%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 1</span>：<code class="language-plaintext highlighter-rouge">Wage</code> 数据集。<strong>左图</strong>：实线表示 <code class="language-plaintext highlighter-rouge">wage</code> (单位：千美元) 关于 <code class="language-plaintext highlighter-rouge">age</code> 的 $4$ 阶多项式模型曲线，用最小二乘法拟合；虚线表示 $95\%$ 置信区间。<strong>右图</strong>：针对二元变量 <code class="language-plaintext highlighter-rouge">wage &gt;250</code> 的逻辑回归模型建模结果，通常采用 $4$ 阶多项式，蓝色实线表示 <code class="language-plaintext highlighter-rouge">wage &gt;250</code> 的后验概率，虚线则是估计的 $95\%$ 置信区间。</span></p>

<p>首先创建一些新的变量 $X_1=X, X_2=X^2,\dots$，然后按照多元线性回归的方式拟合它们。</p>

<p>这里，我们真正关心的并非回归系数，而是在任意一个 $x_0$ 处的拟合函数值：</p>

<script type="math/tex; mode=display">\hat f(x_0) = \hat \beta_0 + \hat \beta_1 x_0+ \hat \beta_2 x_0^2+ \hat \beta_3 x_0^3+ \hat \beta_4 x_0^4</script>

<p>由于 $\hat f(x_0)$ 是一个关于 $\hat \beta_{\ell}$ 的线性函数，我们可以得到一个在任意 $x_0$ 处的 <strong>点方差 (pointwise-variances)</strong> $\mathrm{Var}[\hat f(x_0)]$ 的简单表示。在图 1 中，我们已经计算了 $x_0$ 值网格上的拟合和逐点标准误差。</p>

<p>下节内容：非线性模型</p>
:ET