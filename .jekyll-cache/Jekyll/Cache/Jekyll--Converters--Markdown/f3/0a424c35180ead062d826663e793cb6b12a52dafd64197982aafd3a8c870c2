I".5<h1 id="lecture-05-重抽样方法">Lecture 05 重抽样方法</h1>

<p><strong>参考教材</strong>：</p>

<ul>
  <li><em>Gareth, J., Daniela, W., Trevor, H., &amp; Robert, T. (2013). An intruduction to statistical learning: with applications in R. Spinger.</em></li>
  <li><em>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Spinger Science &amp; Business Media.</em></li>
</ul>

<p>现代统计学中，<strong>重抽样方法 (resampling method)</strong> 是一种不可或缺的工具。这种方法通过反复从训练集中抽取样本，然后对每一个样本重新拟合一个感兴趣的模型，来获取关于拟合模型的附加信息 (例如，它可以提供测试集上预测误差的估计值，以及我们参数估计值的标准差和偏差)。</p>

<p>在本节课中，我们主要讨论两种 <strong>重抽样方法 (resampling)</strong>：<strong>交叉验证法</strong> 和 <strong>bootstrap</strong>。</p>

<h2 id="1-交叉验证法">1. 交叉验证法</h2>

<h3 id="11-训练误差-vs-测试误差">1.1 训练误差 vs. 测试误差</h3>

<p>回忆一下 <strong>测试误差 (test error)</strong> 和 <strong>训练误差 (training error)</strong> 之间的区别：</p>

<ul>
  <li>
    <p><strong>测试误差</strong> 是使用某种统计学习方法预测在一个新的观测 (即在训练模型时没有用到的一个观测) 上的响应值所产生的平均误差。</p>
  </li>
  <li>
    <p>相反，通过将统计学习方法用于训练观测上，可以轻松计算出 <strong>训练误差</strong>。</p>
  </li>
</ul>

<p>但是，训练错误率通常跟测试错误率有很大差别，尤其是表现为前者可能会 <strong>严重低估</strong> 后者。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-135808%402x.png" width="70%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 1</span>：模型复杂度 vs. 预测误差。红色曲线代表测试误差，蓝色曲线代表训练误差。随着模型复杂度增加：模型将具有低偏差，高方差；训练误差逐渐下降；而测试误差将先下降再上升，呈现出 U 型。</span></p>

<h4 id="估计预测误差">估计预测误差</h4>

<p><strong>最佳解决方案</strong>：准备一个非常大的指定测试数据集。然而，通常很难获得这样的数据集。</p>

<p>一些方法通过对训练错误率进行数学修正来估计测试错误率。其中包括 <strong>$C_p$ 统计量</strong>、<strong>$\textit{AIC}$</strong> 和 <strong>$\textit{BIC}$</strong>，我们将在后面课程中讨论这些方法。</p>

<p>在这里，我们考虑一类方法：在拟合过程中，<strong>保留 (holding out)</strong> 训练观测的一个子集，然后对保留的观测运用统计学习方法，从而来估计其测试错误率。</p>

<h3 id="12-验证集方法">1.2 验证集方法</h3>

<p>如果我们想要估计在一个观测数据集上拟合一种指定的统计学习方法所产生的测试误差，图 2 所示的 <strong>验证集方法 (validation-set approach)</strong> 就是一种非常简单的方法。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-141439%402x.png" width="60%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 2</span>：验证集方法的原理图。一个包含 $n$ 个观测的数据集被随机地分为一个训练集 (左下部分，包含观测 7、22、13 及其他观测) 和一个验证集 (右下部分，包含观测 91 及其他观测)。验证集方法是一种先在训练集上拟合统计学习方法，然后在验证集上评价其表现的方法。</span></p>

<p>在这里，我们将可用的样本集随机分为两部分：<strong>训练集 (training set)</strong> 和 <strong>验证集 (validation set)</strong>，又称 <strong>保留集 (hold-out set)</strong>。</p>

<p>我们在训练集上拟合模型，然后用拟合的模型来预测验证集中观测的响应值。</p>

<p>最后得到的验证集误差提供了一个对于测试误差的估计。对于定量响应，通常使用 MSE 进行评估；对于定性 (离散) 响应，则使用误分类率进行评估。</p>

<h4 id="例子汽车数据集">例子：汽车数据集</h4>

<p>我们将在 <code class="language-plaintext highlighter-rouge">Auto</code> 数据集上说明验证集方法的原理。回忆之前我们提到，<code class="language-plaintext highlighter-rouge">mpg</code> 和 <code class="language-plaintext highlighter-rouge">horsepower</code> 之间似乎存在非线性关系，而加入 <code class="language-plaintext highlighter-rouge">horsepower</code> 和 <code class="language-plaintext highlighter-rouge">horsepower</code>$^2$ 后的模型要比仅使用线性项拟合的模型的预测效果更好。那么很自然就会产生这样一个疑问：用三次或更高次项来拟合模型的效果是不是更好呢？</p>

<p>之前，我们通过考察用三次及更高次多项式进行线性回归所得到的 p 值回答了这个问题。这里，我们也可以用验证集方法来解决这个问题。</p>

<p>现在，我们想要比较仅包含线性项与包含高阶多项式项的线性回归模型的拟合效果。</p>

<p>我们将 $392$ 个观测值随机分为两组：一个包含 $196$ 个数据点的训练集，一个包含剩余 $196$ 个观测点的验证集。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-144702%402x.png" width="80%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 3</span>：在 <code class="language-plaintext highlighter-rouge">Auto</code> 数据集上，用验证集方法来估计用 <code class="language-plaintext highlighter-rouge">horsepower</code> 的多项式函数来预测 <code class="language-plaintext highlighter-rouge">mpg</code>所产生的测试误差。<strong>左图</strong>：用一种随机划分将数据集分为训练集和验证集，所产生的验证误差估计。<strong>右图</strong>：重复运用验证集方法十次，每次使用一种不同的随机划分将数据集分为训练集和验证集，图中反映了用验证集方法所产生的测试均方误差估计的波动性。</span></p>

<h4 id="验证集方法的缺点">验证集方法的缺点</h4>

<p>验证集方法的原理很简单，且易于执行。但它有 <strong>两个潜在缺陷</strong>：</p>

<ol>
  <li>
    <p>测试误差的验证集法估计的 <strong>波动很大</strong> (如图 3 右图所示)，这取决于具体哪些观测被包括在训练集中，哪些观测被包括在验证集中。</p>
  </li>
  <li>
    <p>在验证集方法中，只有一部分观测 (即那些被包含在训练集而非验证集中的观测) 被用于拟合模型。由于训练样本越少，统计学习方法的表现越差，这意味着，验证集误差可能会 <strong>高估</strong> 在整个数据集上拟合模型所得到的测试误差。</p>
  </li>
</ol>

<h3 id="13-k-折交叉验证">1.3 $K$-折交叉验证</h3>

<p><strong>$K$-折交叉验证</strong> 是一种广泛用于估计测试误差的方法。</p>

<p>估计值可用于选择最佳模型，并给出最终选择模型的测试误差的相关信息。</p>

<p><strong>核心思想</strong>：将数据随机分为 $K$ 个相等大小的部分。将其中第 $k$ 个部分留出，然后用其余 $K-1$ 个部分的数据来拟合模型，然后对之前留出的第 $k$ 个部分进行预测，并计算其均方误差 $\mathrm{MSE}_k$。依次针对每个部分 $k=1,2,\dots,K$ 重复该过程，然后将结果合并。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-151526%402x.png" width="70%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 4</span>：$5$ 折 CV 方法的原理图。一个包含 $n$ 个观测的数据集被随机地分为 $5$ 个不重叠的组。每一组轮流作为验证集 (图中米黄色部分)，其余组作为训练集 (图中蓝色部分)。通过对最终得到的 $5$ 个均方误差估计求平均来估计测试误差。</span></p>

<p>将包含全部 $n$ 个观测的数据集划分为 $K$ 个部分 $C_1,C_2,\dots,C_K$，其中 $C_k$ 表示第 $k$ 个部分中观测的索引。$n_k$ 表示第 $k$ 个数据集中的观测数量：如果 $n$ 是 $K$ 的整数倍，那么 $n_k=n/K$。</p>

<p>计算 $K$-折 CV 估计：</p>

<script type="math/tex; mode=display">\mathrm{CV}_{(K)}=\sum_{k=1}^{K}\dfrac{n_k}{n} \mathrm{MSE}_k</script>

<p>其中，$\mathrm{MSE}_k = \sum_{i\in C_k} (y_i - \hat y_i)^2 / n_k$，而 $\hat y_i$ 是第 $i$ 个观测的拟合值，它是通过移除第 $k$ 个部分后拟合出的模型得到的。</p>

<h4 id="留一交叉验证">留一交叉验证</h4>

<p>令 $K=n$，将得到 $n$-折 CV，也叫 <strong>留一交叉验证 (leave-one out cross-validation, LOOCV)</strong>。</p>

<p>LOOCV 方法的计算量可能很大，因为模型需要被拟合 $n$ 次。但是，使用最小二乘法来拟合线性或多项式回归时，可以将 LOOCV 的计算成本缩减到与单个模型拟合成本相同。计算公式如下：</p>

<script type="math/tex; mode=display">\mathrm{CV}_{(n)}=\dfrac{1}{n}\sum_{i=1}^{n}\left(\dfrac{y_i - \hat y_i}{1- h_i}\right)^2</script>

<p>其中，$\hat y_i$ 是原始最小二乘拟合的第 $i$ 个拟合值，$h_i$ 是杠杆值 (帽子矩阵的对角线上的第 $i$ 个元素；有关详细信息，请参见教材)。类似于普通的 $\mathrm{MSE}$，区别仅在于第 $i$ 个残差除了一个系数 $1-h_i$。</p>

<p>LOOCV 有时很有用，但通常会使 <strong>数据重组不够充分</strong> (即每次只留出一个观测作为验证集，可能导致每次训练集之间的差异过小)。由于每折观测的估计值高度相关，因此它们的平均值可能具有很高的方差。</p>

<p>通常，更好的选择是 $K=5$ 或 $10$。</p>

<h4 id="k-折-cv-vs-loocv">$K$-折 CV vs. LOOCV</h4>

<p>在 <code class="language-plaintext highlighter-rouge">Auto</code> 数据集上分别用 LOOCV 和 $10$-折 CV 方法，得到用 <code class="language-plaintext highlighter-rouge">horsepower</code> 的多项式函数拟合线性回归模型，来预测 <code class="language-plaintext highlighter-rouge">mpg</code> 所产生的测试集均方误差的一个估计，如图 5 所示。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-155646%402x.png" width="80%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 5</span>：在 <code class="language-plaintext highlighter-rouge">Auto</code> 数据袋上，用交叉验证法来估计用 <code class="language-plaintext highlighter-rouge">horsepower</code> 的多项式函数来预测 <code class="language-plaintext highlighter-rouge">mpg</code> 所产生的测试误差。<strong>左图</strong>：LOOCV 误差曲线。<strong>右图</strong>：分别应用 $10$-折 CV 方法 $9$ 次，每次用一种不同的随机划分将数据分为 $10$ 个部分。图中展示了 $9$ 条略微不同的 CV 误差曲线。</span></p>

<p>从图 5 中的右图可以看到， CV 估计存在一定的波动性，这是由于将观测分为 $10$ 折的划分差异所造成的。但这种波动通常比之前的验证集方法所得的测试误差的波动要小得多 (对比图 3 中的右图)。</p>

<p>当检验真实数据时，测试均方误差的真实值是未知的，因此很难衡量交叉验证估计的精度。所以这里我们采用模拟数据来衡量交叉验证结果的精度。图 6 描述了不同模拟数据集上采用光滑样条法所得到的测试误差的交叉验证估计值和真实值。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-160643%402x.png" width="90%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 6</span>：不同模拟数据集上的测试均方误差的真实值和估计值。蓝色实线为测试均方误差的真实值，黑色虚线为 LOOCV 估计值，橙色实线为 $10$-折 CV 估计值。用 “x” 标注的点表示每条均方误差曲线的最小值点。</span></p>

<p>可以看到，在三个模拟数据集上，这两种交叉验证估计都非常接近。在图 6 的右图中，测试均方误差的真实值和 CV 估计曲线几乎重合。在图 6 的中图中，当模型灵活度较低时，真实值曲线和 CV 估计曲线比较接近，而当模型灵活度较高时，CV 曲线高估了测试集均方误差。在图 6 的左图中，CV 曲线的形状大致正确，但都低估了测试均方误差的真实值。</p>

<h4 id="交叉验证法的其他问题">交叉验证法的其他问题</h4>

<ul>
  <li>由于每个训练集大小仅为原始训练集的 $(K-1)/K$，因此预测误差的估计值通常会向上偏移 (即高估)。</li>
  <li>如前所述，当 $K = n$ 时，LOOCV 将使得上述偏移最小化，但这种情况下，估计值具有较高的方差。</li>
</ul>

<p>K = 5或10为这种偏差方差的折衷提供了一个很好的折衷方案。</p>

<p>下节内容：重抽样方法</p>
:ET