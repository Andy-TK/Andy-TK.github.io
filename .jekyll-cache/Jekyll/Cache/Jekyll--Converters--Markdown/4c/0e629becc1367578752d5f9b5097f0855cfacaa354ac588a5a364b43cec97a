I"K<h1 id="lecture-05-重抽样方法">Lecture 05 重抽样方法</h1>

<p><strong>参考教材</strong>：</p>

<ul>
  <li><em>Gareth, J., Daniela, W., Trevor, H., &amp; Robert, T. (2013). An intruduction to statistical learning: with applications in R. Spinger.</em></li>
  <li><em>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Spinger Science &amp; Business Media.</em></li>
</ul>

<p>现代统计学中，<strong>重抽样方法 (resampling method)</strong> 是一种不可或缺的工具。这种方法通过反复从训练集中抽取样本，然后对每一个样本重新拟合一个感兴趣的模型，来获取关于拟合模型的附加信息 (例如，它可以提供测试集上预测误差的估计值，以及我们参数估计值的标准差和偏差)。</p>

<p>在本节课中，我们主要讨论两种 <strong>重抽样方法 (resampling)</strong>：<strong>交叉验证法</strong> 和 <strong>bootstrap</strong>。</p>

<h2 id="1-交叉验证法">1. 交叉验证法</h2>

<h3 id="11-训练误差-vs-测试误差">1.1 训练误差 vs. 测试误差</h3>

<p>回忆一下 <strong>测试误差 (test error)</strong> 和 <strong>训练误差 (training error)</strong> 之间的区别：</p>

<ul>
  <li>
    <p><strong>测试误差</strong> 是使用某种统计学习方法预测在一个新的观测 (即在训练模型时没有用到的一个观测) 上的响应值所产生的平均误差。</p>
  </li>
  <li>
    <p>相反，通过将统计学习方法用于训练观测上，可以轻松计算出 <strong>训练误差</strong>。</p>
  </li>
</ul>

<p>但是，训练错误率通常跟测试错误率有很大差别，尤其是表现为前者可能会 <strong>严重低估</strong> 后者。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-135808%402x.png" width="70%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 1</span>：模型复杂度 vs. 预测误差。红色曲线代表测试误差，蓝色曲线代表训练误差。随着模型复杂度增加：模型将具有低偏差，高方差；训练误差逐渐下降；而测试误差将先下降再上升，呈现出 U 型。</span></p>

<h4 id="估计预测误差">估计预测误差</h4>

<p><strong>最佳解决方案</strong>：准备一个非常大的指定测试数据集。然而，通常很难获得这样的数据集。</p>

<p>一些方法通过对训练错误率进行数学修正来估计测试错误率。其中包括 <strong>$C_p$ 统计量</strong>、<strong>$\textit{AIC}$</strong> 和 <strong>$\textit{BIC}$</strong>，我们将在后面课程中讨论这些方法。</p>

<p>在这里，我们考虑一类方法：在拟合过程中，<strong>保留 (holding out)</strong> 训练观测的一个子集，然后对保留的观测运用统计学习方法，从而来估计其测试错误率。</p>

<h3 id="12-验证集方法">1.2 验证集方法</h3>

<p>如果我们想要估计在一个观测数据集上拟合一种指定的统计学习方法所产生的测试误差，图 2 所示的 <strong>验证集方法 (validation-set approach)</strong> 就是一种非常简单的方法。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-08-WX20201108-141439%402x.png" width="60%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 2</span>：验证集方法的原理图。一个包含 $n$ 个观测的数据集被随机地分为一个训练集 (左下部分，包含观测 7、22、13 及其他观测) 和一个验证集 (右下部分，包含观测 91 及其他观测)。验证集方法是一种先在训练集上拟合统计学习方法，然后在验证集上评价其表现的方法。</span></p>

<p>在这里，我们将可用的样本集随机分为两部分：<strong>训练集 (training set)</strong> 和 <strong>验证集 (validation set)</strong>，又称 <strong>保留集 (hold-out set)</strong>。</p>

<p>我们在训练集上拟合模型，然后用拟合的模型来预测验证集中观测的响应值。</p>

<p>最后得到的验证集误差提供了一个对于测试误差的估计。对于定量响应，通常使用 MSE 进行评估；对于定性 (离散) 响应，则使用误分类率进行评估。</p>

<h4 id="例子汽车数据集">例子：汽车数据集</h4>

<p>我们将在 <code class="language-plaintext highlighter-rouge">Auto</code> 数据集上说明验证集方法的原理。回忆一下，<code class="language-plaintext highlighter-rouge">mpg</code> 和 <code class="language-plaintext highlighter-rouge">horsepower</code> 之间似乎存在非线性关系，而用 ·horsepower 和 horsepower~ 来预测 m凹 的模型比只用线性项拟合的摸到的预那效果更好。那么很自然就会产生这样一个疑问 2 周三次</p>

<p>或更商次项来拟合模型的效果是不是更好呢?在第3Î在中，通过考察用三次及更高次多项式来 做线性思归所得到的?值回答了这个问题。但也可以用验证法来解决这个问题。</p>

<p>想要在线性回归中比较线性与高阶多项式项</p>

<p>我们将392个观测值随机分为两组，一个训练集包含196个数据点，一个验证集包含剩余的196个观测点。</p>

<p>下节内容：重抽样方法</p>
:ET